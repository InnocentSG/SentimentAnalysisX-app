# -*- coding: utf-8 -*-
"""twitter_senytiment_analysis(github code).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Pr7oMhPzDu9u14YRFSQ-fPgBK49QR2iF
"""

import streamlit as st
import re
import numpy as np
import pandas as pd
import string
import nltk
from nltk.tokenize import RegexpTokenizer
from nltk.stem import PorterStemmer, WordNetLemmatizer
from nltk.corpus import stopwords
import seaborn as sns
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from sklearn.svm import LinearSVC
from sklearn.naive_bayes import BernoulliNB
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import (confusion_matrix,
                           classification_report,
                           roc_curve,
                           auc,
                           precision_recall_curve,
                           average_precision_score)

# Download NLTK resources
nltk.download('wordnet')
nltk.download('stopwords')

# Constants
DATASET_COLUMNS = ['target', 'ids', 'date', 'flag', 'user', 'text']
DATASET_ENCODING = "ISO-8859-1"
SAMPLE_SIZE = 20000

# Set page config
st.set_page_config(
    page_title="Twitter Sentiment Analysis",
    page_icon="üê¶",
    layout="wide"
)

@st.cache_data
def load_dataset():
    """Load and prepare the Twitter sentiment dataset"""
    try:
        df = pd.read_csv("data/training.1600000.processed.noemoticon.csv",
                        encoding=DATASET_ENCODING,
                        names=DATASET_COLUMNS)
    except FileNotFoundError:
        st.error("Dataset not found. Please ensure the CSV file is in the data/ folder")
        st.stop()

    df['target'] = df['target'].replace(4, 1)
    pos_data = df[df['target'] == 1].sample(SAMPLE_SIZE, random_state=42)
    neg_data = df[df['target'] == 0].sample(SAMPLE_SIZE, random_state=42)
    return pd.concat([pos_data, neg_data])

class TextPreprocessor:
    def __init__(self):
        self.stopwords = set(stopwords.words('english'))
        self.stemmer = PorterStemmer()
        self.lemmatizer = WordNetLemmatizer()
        self.tokenizer = RegexpTokenizer(r'\w+')

    def clean_text(self, text):
        """Apply all cleaning steps to text"""
        text = str(text).lower()
        text = self._remove_urls(text)
        text = self._remove_punctuation(text)
        text = self._remove_numbers(text)
        text = self._remove_stopwords(text)
        text = self._remove_repeating_chars(text)
        tokens = self.tokenizer.tokenize(text)
        tokens = [self.stemmer.stem(token) for token in tokens]
        tokens = [self.lemmatizer.lemmatize(token) for token in tokens]
        return ' '.join(tokens)

    def _remove_urls(self, text):
        return re.sub('((www.[^\s]+)|(https?://[^\s]+))', ' ', text)

    def _remove_punctuation(self, text):
        return text.translate(str.maketrans('', '', string.punctuation))

    def _remove_numbers(self, text):
        return re.sub('[0-9]+', '', text)

    def _remove_stopwords(self, text):
        return ' '.join([word for word in text.split() if word not in self.stopwords])

    def _remove_repeating_chars(self, text):
        return re.sub(r'(.)\1+', r'\1', text)

def plot_wordcloud(text, title):
    """Generate and plot word cloud"""
    wc = WordCloud(max_words=1000, width=1600, height=800,
                  collocations=False).generate(text)
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wc)
    ax.set_title(title, fontsize=20)
    ax.axis('off')
    st.pyplot(fig)

def plot_confusion_matrix(y_true, y_pred, classes):
    """Plot confusion matrix with percentages"""
    cm = confusion_matrix(y_true, y_pred)
    group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']
    group_percentages = ['{0:.2%}'.format(value) for value in cm.flatten()/np.sum(cm)]
    labels = [f'{v1}\n{v2}' for v1, v2 in zip(group_names, group_percentages)]
    labels = np.asarray(labels).reshape(2,2)

    fig, ax = plt.subplots(figsize=(8, 6))
    sns.heatmap(cm, annot=labels, cmap='Blues', fmt='',
               xticklabels=classes, yticklabels=classes, ax=ax)
    ax.set_xlabel('Predicted', fontsize=14)
    ax.set_ylabel('Actual', fontsize=14)
    ax.set_title('Confusion Matrix', fontsize=18)
    st.pyplot(fig)

def plot_roc_curve(y_true, y_pred, model_name):
    """Plot ROC curve with AUC score"""
    fpr, tpr, _ = roc_curve(y_true, y_pred)
    roc_auc = auc(fpr, tpr)

    fig, ax = plt.subplots()
    ax.plot(fpr, tpr, color='darkorange', lw=2,
            label=f'ROC curve (AUC = {roc_auc:.2f})')
    ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    ax.set_xlim([0.0, 1.0])
    ax.set_ylim([0.0, 1.05])
    ax.set_xlabel('False Positive Rate')
    ax.set_ylabel('True Positive Rate')
    ax.set_title(f'ROC Curve - {model_name}')
    ax.legend(loc="lower right")
    st.pyplot(fig)

def plot_precision_recall(y_true, y_pred, model_name):
    """Plot Precision-Recall curve"""
    precision, recall, _ = precision_recall_curve(y_true, y_pred)
    avg_precision = average_precision_score(y_true, y_pred)

    fig, ax = plt.subplots()
    ax.plot(recall, precision, lw=2,
            label=f'Precision-Recall (AP = {avg_precision:.2f})')
    ax.set_xlabel('Recall')
    ax.set_ylabel('Precision')
    ax.set_title(f'Precision-Recall Curve - {model_name}')
    ax.legend(loc='best')
    st.pyplot(fig)

def evaluate_model(model, X_test, y_test, model_name):
    """Evaluate model performance"""
    y_pred = model.predict(X_test)

    st.subheader(f"Model Evaluation: {model_name}")

    st.write("Classification Report:")
    report = classification_report(y_test, y_pred, output_dict=True)
    st.table(pd.DataFrame(report).transpose())

    plot_confusion_matrix(y_test, y_pred, ['Negative', 'Positive'])
    plot_roc_curve(y_test, y_pred, model_name)
    plot_precision_recall(y_test, y_pred, model_name)

    return y_pred

def main():
    st.title("üê¶ Twitter Sentiment Analysis")
    st.markdown("""
    This app analyzes sentiment of tweets using different machine learning models.
    """)

    # Load data
    with st.spinner('Loading dataset...'):
        df = load_dataset()

    # EDA Section
    st.header("Exploratory Data Analysis")
    st.write(f"Dataset shape: {df.shape}")
    st.write(f"Class distribution:\n{df['target'].value_counts()}")

    fig, ax = plt.subplots()
    sns.countplot(x='target', data=df, ax=ax)
    ax.set_title('Class Distribution')
    st.pyplot(fig)

    # Preprocessing
    with st.spinner('Preprocessing text...'):
        preprocessor = TextPreprocessor()
        df['cleaned_text'] = df['text'].apply(preprocessor.clean_text)

    # Word Clouds
    st.header("Word Clouds")
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Positive Tweets")
        pos_text = ' '.join(df[df['target']==1]['cleaned_text'])
        plot_wordcloud(pos_text, "Positive Tweets Word Cloud")

    with col2:
        st.subheader("Negative Tweets")
        neg_text = ' '.join(df[df['target']==0]['cleaned_text'])
        plot_wordcloud(neg_text, "Negative Tweets Word Cloud")

    # Model Training
    st.header("Model Training and Evaluation")

    # Split data
    X = df['cleaned_text']
    y = df['target']
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42)

    # Vectorize text
    with st.spinner('Vectorizing text...'):
        vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=100000)
        X_train_vec = vectorizer.fit_transform(X_train)
        X_test_vec = vectorizer.transform(X_test)

    # Select models to run
    st.sidebar.header("Model Selection")
    run_nb = st.sidebar.checkbox("Bernoulli Naive Bayes", True)
    run_svc = st.sidebar.checkbox("Linear SVC", True)
    run_lr = st.sidebar.checkbox("Logistic Regression", True)

    # Train and evaluate selected models
    models = {}
    if run_nb:
        models["Bernoulli Naive Bayes"] = BernoulliNB()
    if run_svc:
        models["Linear SVC"] = LinearSVC(max_iter=1000, random_state=42)
    if run_lr:
        models["Logistic Regression"] = LogisticRegression(max_iter=1000, random_state=42)

    for name, model in models.items():
        with st.spinner(f'Training {name}...'):
            model.fit(X_train_vec, y_train)
            evaluate_model(model, X_test_vec, y_test, name)

    # Live prediction
    st.header("Live Sentiment Prediction")
    user_input = st.text_area("Enter a tweet to analyze its sentiment:", "", height=100)

    if user_input:
        with st.spinner('Analyzing sentiment...'):
            cleaned_input = preprocessor.clean_text(user_input)
            input_vec = vectorizer.transform([cleaned_input])

            results = {}
            for name, model in models.items():
                prediction = model.predict(input_vec)[0]
                results[name] = "Positive" if prediction == 1 else "Negative"

            st.subheader("Prediction Results")
            for model_name, sentiment in results.items():
                st.metric(label=model_name, value=sentiment)

if __name__ == "__main__":
    main()